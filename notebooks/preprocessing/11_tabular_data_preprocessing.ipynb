{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aa708e7",
   "metadata": {},
   "source": [
    "# Line up precipitation and streamflow historical tabular data\n",
    "\n",
    "Before lining up tabular data, the following steps is taken to clean and prepare the data for next steps:\n",
    "\n",
    "1. Convert streamflow cubic foot per second to cubic meters per second.\n",
    "2. Fill in missing values for precipitation stations with zeros (the original source file omits non precipitation data. Therefore we assume all non precipitation dates to be zero).\n",
    "3. Convert height of precipitation in foot to meter. \n",
    "4. Separete quickflow from baseflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8781d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbc7c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Modules\n",
    "project_root_path = Path.cwd().parent.parent\n",
    "sys.path.append(str(project_root_path / 'src'))\n",
    "\n",
    "from preprocessing.lyne_hollick_filter  import lyne_hollick_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1db738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define help function\n",
    "import re\n",
    "import ast\n",
    "from typing import Any\n",
    "\n",
    "def parse_np_float64_string(s: str) -> Any:\n",
    "    \"\"\"\n",
    "    Safely parse a string representing a list/dict containing np.float64 calls.\n",
    "    It replaces np.float64(NUMBER) with NUMBER and evaluates the cleaned string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s : str\n",
    "        The string to parse.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Any\n",
    "        The resulting Python object (list, dict, etc.).\n",
    "    \"\"\"\n",
    "    # Replace np.float64(NUMBER) with NUMBER\n",
    "    cleaned = re.sub(r'np\\.float64\\(([^)]+)\\)', r'\\1', s)\n",
    "    # Safely parse as Python literal\n",
    "    return ast.literal_eval(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aeae98",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77667550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "vector_ppt_path = project_root_path / 'data/silver/geo/gpkg/study_area_ppt_stn.gpkg'\n",
    "wsdir = project_root_path / 'data/gold/geo/gpkg/watersheds_with_thiessen_info'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "375483a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the watershed data\n",
    "ws_list_path_list = wsdir.glob('*.gpkg')\n",
    "ws_gdf_list = []\n",
    "for ws_path in ws_list_path_list:\n",
    "    ws = gpd.read_file(ws_path)\n",
    "    ws_gdf_list.append(ws)\n",
    "\n",
    "ppt_gdf = gpd.read_file(vector_ppt_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951502c",
   "metadata": {},
   "source": [
    "## Line up historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dd357f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean streaflow data\n",
    "def clean_streamflow_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df['discharge'] = df['discharge_cfs']* (0.3048**3)\n",
    "    df = df[['dateTime','discharge']]\n",
    "    df.columns = ['date', 'discharge']\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to  clean precipitation data\n",
    "def clean_ppt_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['date'] = df['date'].dt.tz_localize('UTC')\n",
    "    df['height'] = df['height']*0.3048\n",
    "    df['height'] = df['height'].fillna(0.0)\n",
    "    df = df[['date', 'height']]\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to line up the data\n",
    "def line_up_data(ws_gdf: gpd.GeoDataFrame, ppt_gdf: gpd.GeoDataFrame, streamflow_data_dir: Path, ppt_data_dir: Path) -> pd.DataFrame:\n",
    "    \n",
    "    # Get metadata for the watershed\n",
    "    id = ws_gdf['stnid'].iloc[0]\n",
    "    dict_data = parse_np_float64_string(ws_gdf['intersecting_ppt_info'].iloc[0])\n",
    "    ppt_ids = [id['ppt_stnid'] for id in dict_data]\n",
    "    stn_weight = [d['relative_area'] for d in dict_data]\n",
    "    \n",
    "    # Load and clean tabular streamflow data for the watershed\n",
    "    streamflow_path = streamflow_data_dir / f'streamflow_{id}.parquet'\n",
    "    if not streamflow_path.exists():\n",
    "        raise FileNotFoundError(f\"Streamflow data for watershed {id} not found at {streamflow_path}\")\n",
    "    streamflow_df = pd.read_parquet(streamflow_path)\n",
    "    streamflow_df = clean_streamflow_data(streamflow_df)\n",
    "\n",
    "    # Load and clean precipitation data for each ppt station in the watershed\n",
    "    for sntid, weight in zip(ppt_ids, stn_weight):\n",
    "        ppt_path = ppt_data_dir / f'{sntid}.parquet'\n",
    "        if not ppt_path.exists():\n",
    "            raise FileNotFoundError(f\"Precipitation data for station {sntid} not found at {ppt_path}\")\n",
    "\n",
    "        ppt_df = pd.read_parquet(ppt_path)\n",
    "        ppt_df = clean_ppt_data(ppt_df)\n",
    "        ppt_df = ppt_df.rename(columns={'height': f'height_{sntid}'})\n",
    "\n",
    "        # Left join the streamflow data with the precipitation data\n",
    "        streamflow_df = streamflow_df.merge(\n",
    "            ppt_df,\n",
    "            how='left',\n",
    "            on='date'\n",
    "        )\n",
    "\n",
    "        # Update weighted average height\n",
    "        if 'height' not in streamflow_df.columns:\n",
    "            streamflow_df['height'] = streamflow_df[f'height_{sntid}']* weight\n",
    "        else:\n",
    "            streamflow_df['height'] += streamflow_df[f'height_{sntid}'] * weight\n",
    "    \n",
    "    # Clip date range to the available precipitation data\n",
    "    return streamflow_df.dropna(subset=['height']), id\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55ba3d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[us, UTC]",
         "type": "unknown"
        },
        {
         "name": "discharge",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "height_USC00361726",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "height",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "height_USC00366111",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "cb919bb1-a8b0-4c26-94b5-f7333a88d61d",
       "rows": [
        [
         "1996",
         "2014-02-25 00:00:00+00:00",
         "240.97636449792003",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "1997",
         "2014-02-25 00:15:00+00:00",
         "240.12685910016003",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "1998",
         "2014-02-25 00:30:00+00:00",
         "239.56052216832003",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "1999",
         "2014-02-25 00:45:00+00:00",
         "238.71101677056004",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2000",
         "2014-02-25 01:00:00+00:00",
         "238.71101677056004",
         "0.0",
         "0.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>discharge</th>\n",
       "      <th>height_USC00361726</th>\n",
       "      <th>height</th>\n",
       "      <th>height_USC00366111</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2014-02-25 00:00:00+00:00</td>\n",
       "      <td>240.976364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2014-02-25 00:15:00+00:00</td>\n",
       "      <td>240.126859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>2014-02-25 00:30:00+00:00</td>\n",
       "      <td>239.560522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2014-02-25 00:45:00+00:00</td>\n",
       "      <td>238.711017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>2014-02-25 01:00:00+00:00</td>\n",
       "      <td>238.711017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date   discharge  height_USC00361726  height  \\\n",
       "1996 2014-02-25 00:00:00+00:00  240.976364                 0.0     0.0   \n",
       "1997 2014-02-25 00:15:00+00:00  240.126859                 0.0     0.0   \n",
       "1998 2014-02-25 00:30:00+00:00  239.560522                 0.0     0.0   \n",
       "1999 2014-02-25 00:45:00+00:00  238.711017                 0.0     0.0   \n",
       "2000 2014-02-25 01:00:00+00:00  238.711017                 0.0     0.0   \n",
       "\n",
       "      height_USC00366111  \n",
       "1996                 0.0  \n",
       "1997                 0.0  \n",
       "1998                 0.0  \n",
       "1999                 0.0  \n",
       "2000                 0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamflow_data_dir = project_root_path / 'data/bronze/tabular/streamflow'\n",
    "ppt_dir = project_root_path / 'data/silver/tabular/precipitation'\n",
    "lined_up_data, ws_id = line_up_data(ws_gdf_list[2], ppt_gdf, streamflow_data_dir, ppt_dir)\n",
    "lined_up_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e013e91",
   "metadata": {},
   "source": [
    "#### Baseflow separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a59e0845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[us, UTC]",
         "type": "unknown"
        },
        {
         "name": "discharge",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "height_USC00361726",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "height",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "height_USC00366111",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "baseflow",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "076d5e39-90f2-41ec-b8f2-10fd46205cc2",
       "rows": [
        [
         "1996",
         "2014-02-25 00:00:00+00:00",
         "240.97636449792003",
         "0.0",
         "0.0",
         "0.0",
         "122.62875348707783"
        ],
        [
         "1997",
         "2014-02-25 00:15:00+00:00",
         "240.12685910016003",
         "0.0",
         "0.0",
         "0.0",
         "104.08201566321135"
        ],
        [
         "1998",
         "2014-02-25 00:30:00+00:00",
         "239.56052216832003",
         "0.0",
         "0.0",
         "0.0",
         "87.86014267727185"
        ],
        [
         "1999",
         "2014-02-25 00:45:00+00:00",
         "238.71101677056004",
         "0.0",
         "0.0",
         "0.0",
         "73.19166498457378"
        ],
        [
         "2000",
         "2014-02-25 01:00:00+00:00",
         "238.71101677056004",
         "0.0",
         "0.0",
         "0.0",
         "61.00280507509766"
        ],
        [
         "2001",
         "2014-02-25 01:15:00+00:00",
         "238.14467983872004",
         "0.0",
         "0.0",
         "0.0",
         "49.70203151552014"
        ],
        [
         "2002",
         "2014-02-25 01:30:00+00:00",
         "238.14467983872004",
         "0.0",
         "0.0",
         "0.0",
         "40.27369512489456"
        ],
        [
         "2003",
         "2014-02-25 01:45:00+00:00",
         "237.29517444096004",
         "0.0",
         "0.0",
         "0.0",
         "31.17787680588542"
        ],
        [
         "2004",
         "2014-02-25 02:00:00+00:00",
         "237.29517444096004",
         "0.0",
         "0.0",
         "0.0",
         "23.990477350290714"
        ],
        [
         "2005",
         "2014-02-25 02:15:00+00:00",
         "237.29517444096004",
         "0.0",
         "0.0",
         "0.0",
         "17.719985831535123"
        ],
        [
         "2006",
         "2014-02-25 02:30:00+00:00",
         "237.29517444096004",
         "0.0",
         "0.0",
         "0.0",
         "12.270444389857495"
        ],
        [
         "2007",
         "2014-02-25 02:45:00+00:00",
         "237.29517444096004",
         "0.0",
         "0.0",
         "0.0",
         "7.555224416410205"
        ],
        [
         "2008",
         "2014-02-25 03:00:00+00:00",
         "237.29517444096004",
         "0.0",
         "0.0",
         "0.0",
         "3.4961744836449915"
        ],
        [
         "2009",
         "2014-02-25 03:15:00+00:00",
         "237.29517444096004",
         "0.0",
         "0.0",
         "0.0",
         "0.022844221677051024"
        ],
        [
         "2010",
         "2014-02-25 03:30:00+00:00",
         "237.29517444096004",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2011",
         "2014-02-25 03:45:00+00:00",
         "237.29517444096004",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2012",
         "2014-02-25 04:00:00+00:00",
         "237.29517444096004",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2013",
         "2014-02-25 04:15:00+00:00",
         "237.29517444096004",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2014",
         "2014-02-25 04:30:00+00:00",
         "237.29517444096004",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2015",
         "2014-02-25 04:45:00+00:00",
         "237.29517444096004",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2016",
         "2014-02-25 05:00:00+00:00",
         "237.29517444096004",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2017",
         "2014-02-25 05:15:00+00:00",
         "236.44566904320004",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2018",
         "2014-02-25 05:30:00+00:00",
         "235.87933211136004",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2019",
         "2014-02-25 05:45:00+00:00",
         "235.87933211136004",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2020",
         "2014-02-25 06:00:00+00:00",
         "235.02982671360004",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2021",
         "2014-02-25 06:15:00+00:00",
         "234.46348978176005",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2022",
         "2014-02-25 06:30:00+00:00",
         "234.46348978176005",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2023",
         "2014-02-25 06:45:00+00:00",
         "233.04764745216002",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2024",
         "2014-02-25 07:00:00+00:00",
         "233.04764745216002",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2025",
         "2014-02-25 07:15:00+00:00",
         "231.63180512256002",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2026",
         "2014-02-25 07:30:00+00:00",
         "231.63180512256002",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2027",
         "2014-02-25 07:45:00+00:00",
         "231.06546819072003",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2028",
         "2014-02-25 08:00:00+00:00",
         "230.49913125888003",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2029",
         "2014-02-25 08:15:00+00:00",
         "229.93279432704003",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2030",
         "2014-02-25 08:30:00+00:00",
         "229.36645739520003",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2031",
         "2014-02-25 08:45:00+00:00",
         "228.51695199744003",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2032",
         "2014-02-25 09:00:00+00:00",
         "227.95061506560003",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2033",
         "2014-02-25 09:15:00+00:00",
         "227.38427813376003",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2034",
         "2014-02-25 09:30:00+00:00",
         "226.81794120192004",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2035",
         "2014-02-25 09:45:00+00:00",
         "226.25160427008004",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2036",
         "2014-02-25 10:00:00+00:00",
         "225.68526733824004",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2037",
         "2014-02-25 10:15:00+00:00",
         "225.11893040640004",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2038",
         "2014-02-25 10:30:00+00:00",
         "224.55259347456004",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2039",
         "2014-02-25 10:45:00+00:00",
         "224.55259347456004",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2040",
         "2014-02-25 11:00:00+00:00",
         "223.70308807680004",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2041",
         "2014-02-25 11:15:00+00:00",
         "223.13675114496004",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2042",
         "2014-02-25 11:30:00+00:00",
         "222.00407728128005",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2043",
         "2014-02-25 11:45:00+00:00",
         "221.43774034944002",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2044",
         "2014-02-25 12:00:00+00:00",
         "220.87140341760002",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2045",
         "2014-02-25 12:15:00+00:00",
         "220.30506648576002",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 372883
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>discharge</th>\n",
       "      <th>height_USC00361726</th>\n",
       "      <th>height</th>\n",
       "      <th>height_USC00366111</th>\n",
       "      <th>baseflow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2014-02-25 00:00:00+00:00</td>\n",
       "      <td>240.976364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.628753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2014-02-25 00:15:00+00:00</td>\n",
       "      <td>240.126859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.082016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>2014-02-25 00:30:00+00:00</td>\n",
       "      <td>239.560522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.860143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2014-02-25 00:45:00+00:00</td>\n",
       "      <td>238.711017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.191665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>2014-02-25 01:00:00+00:00</td>\n",
       "      <td>238.711017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.002805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374874</th>\n",
       "      <td>2025-04-01 22:45:00+00:00</td>\n",
       "      <td>60.598052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.044401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374875</th>\n",
       "      <td>2025-04-01 23:00:00+00:00</td>\n",
       "      <td>60.598052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.915148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374876</th>\n",
       "      <td>2025-04-01 23:15:00+00:00</td>\n",
       "      <td>60.881220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.081438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374877</th>\n",
       "      <td>2025-04-01 23:30:00+00:00</td>\n",
       "      <td>61.164389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.249573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374878</th>\n",
       "      <td>2025-04-01 23:45:00+00:00</td>\n",
       "      <td>61.164389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.147963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372883 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            date   discharge  height_USC00361726  height  \\\n",
       "1996   2014-02-25 00:00:00+00:00  240.976364                 0.0     0.0   \n",
       "1997   2014-02-25 00:15:00+00:00  240.126859                 0.0     0.0   \n",
       "1998   2014-02-25 00:30:00+00:00  239.560522                 0.0     0.0   \n",
       "1999   2014-02-25 00:45:00+00:00  238.711017                 0.0     0.0   \n",
       "2000   2014-02-25 01:00:00+00:00  238.711017                 0.0     0.0   \n",
       "...                          ...         ...                 ...     ...   \n",
       "374874 2025-04-01 22:45:00+00:00   60.598052                 0.0     0.0   \n",
       "374875 2025-04-01 23:00:00+00:00   60.598052                 0.0     0.0   \n",
       "374876 2025-04-01 23:15:00+00:00   60.881220                 0.0     0.0   \n",
       "374877 2025-04-01 23:30:00+00:00   61.164389                 0.0     0.0   \n",
       "374878 2025-04-01 23:45:00+00:00   61.164389                 0.0     0.0   \n",
       "\n",
       "        height_USC00366111    baseflow  \n",
       "1996                   0.0  122.628753  \n",
       "1997                   0.0  104.082016  \n",
       "1998                   0.0   87.860143  \n",
       "1999                   0.0   73.191665  \n",
       "2000                   0.0   61.002805  \n",
       "...                    ...         ...  \n",
       "374874                 0.0    1.044401  \n",
       "374875                 0.0    0.915148  \n",
       "374876                 0.0    1.081438  \n",
       "374877                 0.0    1.249573  \n",
       "374878                 0.0    1.147963  \n",
       "\n",
       "[372883 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lined_up_data['baseflow'] = lyne_hollick_filter(lined_up_data['discharge'])\n",
    "lined_up_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc04324",
   "metadata": {},
   "source": [
    "### Batch Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef7357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fe5d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661a06dd318746ce89f047245665e2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lining up data for watersheds:   0%|          | 0/508 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ArrowKeyError",
     "evalue": "Attempted to register factory for scheme 'file' but that scheme is already registered.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mArrowKeyError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# Save the lined up data to a file\u001b[39;00m\n\u001b[32m     13\u001b[39m     output_path = streamflow_data_dir / \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mlined_up_streamflow_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mws_gdf[\u001b[33m\"\u001b[39m\u001b[33mstnid\u001b[39m\u001b[33m\"\u001b[39m].iloc[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.parquet\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[43mlined_up_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError processing watershed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mws_gdf[\u001b[33m'\u001b[39m\u001b[33mstnid\u001b[39m\u001b[33m'\u001b[39m].iloc[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Science Projects/ML-ModClark-IUH-Model/venv/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Science Projects/ML-ModClark-IUH-Model/venv/lib/python3.12/site-packages/pandas/core/frame.py:3113\u001b[39m, in \u001b[36mDataFrame.to_parquet\u001b[39m\u001b[34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[39m\n\u001b[32m   3032\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3033\u001b[39m \u001b[33;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[32m   3034\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3109\u001b[39m \u001b[33;03m>>> content = f.read()\u001b[39;00m\n\u001b[32m   3110\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3111\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparquet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[32m-> \u001b[39m\u001b[32m3113\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3114\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3115\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3117\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3119\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3121\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3122\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Science Projects/ML-ModClark-IUH-Model/venv/lib/python3.12/site-packages/pandas/io/parquet.py:480\u001b[39m, in \u001b[36mto_parquet\u001b[39m\u001b[34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m impl = get_engine(engine)\n\u001b[32m    478\u001b[39m path_or_buf: FilePath | WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] = io.BytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, io.BytesIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Science Projects/ML-ModClark-IUH-Model/venv/lib/python3.12/site-packages/pandas/io/parquet.py:228\u001b[39m, in \u001b[36mPyArrowImpl.write\u001b[39m\u001b[34m(self, df, path, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[39m\n\u001b[32m    218\u001b[39m         \u001b[38;5;28mself\u001b[39m.api.parquet.write_to_dataset(\n\u001b[32m    219\u001b[39m             table,\n\u001b[32m    220\u001b[39m             path_or_handle,\n\u001b[32m   (...)\u001b[39m\u001b[32m    224\u001b[39m             **kwargs,\n\u001b[32m    225\u001b[39m         )\n\u001b[32m    226\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    227\u001b[39m         \u001b[38;5;66;03m# write to single output file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparquet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    236\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Science Projects/ML-ModClark-IUH-Model/venv/lib/python3.12/site-packages/pyarrow/parquet/core.py:1902\u001b[39m, in \u001b[36mwrite_table\u001b[39m\u001b[34m(table, where, row_group_size, version, use_dictionary, compression, write_statistics, use_deprecated_int96_timestamps, coerce_timestamps, allow_truncated_timestamps, data_page_size, flavor, filesystem, compression_level, use_byte_stream_split, column_encoding, data_page_version, use_compliant_nested_type, encryption_properties, write_batch_size, dictionary_pagesize_limit, store_schema, write_page_index, write_page_checksum, sorting_columns, store_decimal_as_integer, **kwargs)\u001b[39m\n\u001b[32m   1900\u001b[39m use_int96 = use_deprecated_int96_timestamps\n\u001b[32m   1901\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1902\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mParquetWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1903\u001b[39m \u001b[43m            \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1904\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1905\u001b[39m \u001b[43m            \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1906\u001b[39m \u001b[43m            \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1907\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_dictionary\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_dictionary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1908\u001b[39m \u001b[43m            \u001b[49m\u001b[43mwrite_statistics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrite_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1909\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcoerce_timestamps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_timestamps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1910\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata_page_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_page_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1911\u001b[39m \u001b[43m            \u001b[49m\u001b[43mallow_truncated_timestamps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_truncated_timestamps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1912\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1913\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_deprecated_int96_timestamps\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_int96\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1914\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompression_level\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_byte_stream_split\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_byte_stream_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1916\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcolumn_encoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumn_encoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1917\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata_page_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_page_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1918\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_compliant_nested_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_compliant_nested_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1919\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencryption_properties\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencryption_properties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[43m            \u001b[49m\u001b[43mwrite_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrite_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1921\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdictionary_pagesize_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdictionary_pagesize_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1922\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstore_schema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstore_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1923\u001b[39m \u001b[43m            \u001b[49m\u001b[43mwrite_page_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrite_page_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1924\u001b[39m \u001b[43m            \u001b[49m\u001b[43mwrite_page_checksum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrite_page_checksum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m            \u001b[49m\u001b[43msorting_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43msorting_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstore_decimal_as_integer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstore_decimal_as_integer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1927\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[32m   1928\u001b[39m         writer.write_table(table, row_group_size=row_group_size)\n\u001b[32m   1929\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Science Projects/ML-ModClark-IUH-Model/venv/lib/python3.12/site-packages/pyarrow/parquet/core.py:1010\u001b[39m, in \u001b[36mParquetWriter.__init__\u001b[39m\u001b[34m(self, where, schema, filesystem, flavor, version, use_dictionary, compression, write_statistics, use_deprecated_int96_timestamps, compression_level, use_byte_stream_split, column_encoding, writer_engine_version, data_page_version, use_compliant_nested_type, encryption_properties, write_batch_size, dictionary_pagesize_limit, store_schema, write_page_index, write_page_checksum, sorting_columns, store_decimal_as_integer, **options)\u001b[39m\n\u001b[32m   1006\u001b[39m \u001b[38;5;66;03m# If we open a file using a filesystem, store file handle so we can be\u001b[39;00m\n\u001b[32m   1007\u001b[39m \u001b[38;5;66;03m# sure to close it when `self.close` is called.\u001b[39;00m\n\u001b[32m   1008\u001b[39m \u001b[38;5;28mself\u001b[39m.file_handle = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m filesystem, path = \u001b[43m_resolve_filesystem_and_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filesystem \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1012\u001b[39m     \u001b[38;5;66;03m# ARROW-10480: do not auto-detect compression.  While\u001b[39;00m\n\u001b[32m   1013\u001b[39m     \u001b[38;5;66;03m# a filename like foo.parquet.gz is nonconforming, it\u001b[39;00m\n\u001b[32m   1014\u001b[39m     \u001b[38;5;66;03m# shouldn't implicitly apply compression.\u001b[39;00m\n\u001b[32m   1015\u001b[39m     sink = \u001b[38;5;28mself\u001b[39m.file_handle = filesystem.open_output_stream(\n\u001b[32m   1016\u001b[39m         path, compression=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Science Projects/ML-ModClark-IUH-Model/venv/lib/python3.12/site-packages/pyarrow/fs.py:165\u001b[39m, in \u001b[36m_resolve_filesystem_and_path\u001b[39m\u001b[34m(path, filesystem, memory_map)\u001b[39m\n\u001b[32m    160\u001b[39m path = _stringify_path(path)\n\u001b[32m    162\u001b[39m \u001b[38;5;66;03m# if filesystem is not given, try to automatically determine one\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;66;03m# first check if the file exists as a local (relative) file path\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# if not then try to parse the path as an URI\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m filesystem = \u001b[43mLocalFileSystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_mmap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    168\u001b[39m     file_info = filesystem.get_file_info(path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Science Projects/ML-ModClark-IUH-Model/venv/lib/python3.12/site-packages/pyarrow/_fs.pyx:1112\u001b[39m, in \u001b[36mpyarrow._fs.LocalFileSystem.__init__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Science Projects/ML-ModClark-IUH-Model/venv/lib/python3.12/site-packages/pyarrow/error.pxi:155\u001b[39m, in \u001b[36mpyarrow.lib.pyarrow_internal_check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Science Projects/ML-ModClark-IUH-Model/venv/lib/python3.12/site-packages/pyarrow/error.pxi:92\u001b[39m, in \u001b[36mpyarrow.lib.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mArrowKeyError\u001b[39m: Attempted to register factory for scheme 'file' but that scheme is already registered."
     ]
    }
   ],
   "source": [
    "\n",
    "# Define paths\n",
    "\n",
    "output_dir = project_root_path / 'data/gold/tabular/lined_up_streamflow'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "err_log = []\n",
    "for ws_gdf in tqdm(ws_gdf_list, desc=\"Lining up data for watersheds\"):\n",
    "\n",
    "    # Line up the data for each watershed\n",
    "    try:\n",
    "        lined_up_data, ws_id = line_up_data(ws_gdf, ppt_gdf, streamflow_data_dir, ppt_dir)\n",
    "        \n",
    "\n",
    "        # Save the lined up data to a file\n",
    "        output_path = output_dir / f'lined_up_streamflow_{ws_id}.parquet'\n",
    "        lined_up_data.to_parquet(output_path)\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error processing watershed {ws_gdf['stnid'].iloc[0]}: {e}\")\n",
    "line_up_data(ws_gdf_list[2], ppt_gdf, streamflow_data_dir, ppt_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
